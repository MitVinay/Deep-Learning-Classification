{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1481789,"sourceType":"datasetVersion","datasetId":869651}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-26T11:27:26.406373Z","iopub.execute_input":"2023-11-26T11:27:26.406912Z","iopub.status.idle":"2023-11-26T11:27:27.080244Z","shell.execute_reply.started":"2023-11-26T11:27:26.406872Z","shell.execute_reply":"2023-11-26T11:27:27.077941Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/credit-card-customer-churn-prediction/Churn_Modelling.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/credit-card-customer-churn-prediction/Churn_Modelling.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:30.044951Z","iopub.execute_input":"2023-11-26T11:27:30.045576Z","iopub.status.idle":"2023-11-26T11:27:30.105871Z","shell.execute_reply.started":"2023-11-26T11:27:30.045539Z","shell.execute_reply":"2023-11-26T11:27:30.104948Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:32.320643Z","iopub.execute_input":"2023-11-26T11:27:32.321738Z","iopub.status.idle":"2023-11-26T11:27:32.372122Z","shell.execute_reply.started":"2023-11-26T11:27:32.321692Z","shell.execute_reply":"2023-11-26T11:27:32.370216Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(10000, 14)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n0          1    15634602  Hargrave          619    France  Female   42   \n1          2    15647311      Hill          608     Spain  Female   41   \n2          3    15619304      Onio          502    France  Female   42   \n3          4    15701354      Boni          699    France  Female   39   \n4          5    15737888  Mitchell          850     Spain  Female   43   \n\n   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n0       2       0.00              1          1               1   \n1       1   83807.86              1          0               1   \n2       8  159660.80              3          1               0   \n3       1       0.00              2          0               0   \n4       2  125510.82              1          1               1   \n\n   EstimatedSalary  Exited  \n0        101348.88       1  \n1        112542.58       0  \n2        113931.57       1  \n3         93826.63       0  \n4         79084.10       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>15634602</td>\n      <td>Hargrave</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>15647311</td>\n      <td>Hill</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>15619304</td>\n      <td>Onio</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>15701354</td>\n      <td>Boni</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>15737888</td>\n      <td>Mitchell</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# checking missing values\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:35.496588Z","iopub.execute_input":"2023-11-26T11:27:35.497332Z","iopub.status.idle":"2023-11-26T11:27:35.536201Z","shell.execute_reply.started":"2023-11-26T11:27:35.497295Z","shell.execute_reply":"2023-11-26T11:27:35.535227Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000 entries, 0 to 9999\nData columns (total 14 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   RowNumber        10000 non-null  int64  \n 1   CustomerId       10000 non-null  int64  \n 2   Surname          10000 non-null  object \n 3   CreditScore      10000 non-null  int64  \n 4   Geography        10000 non-null  object \n 5   Gender           10000 non-null  object \n 6   Age              10000 non-null  int64  \n 7   Tenure           10000 non-null  int64  \n 8   Balance          10000 non-null  float64\n 9   NumOfProducts    10000 non-null  int64  \n 10  HasCrCard        10000 non-null  int64  \n 11  IsActiveMember   10000 non-null  int64  \n 12  EstimatedSalary  10000 non-null  float64\n 13  Exited           10000 non-null  int64  \ndtypes: float64(2), int64(9), object(3)\nmemory usage: 1.1+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# checking total number of duplicated rows\ndf.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:37.952188Z","iopub.execute_input":"2023-11-26T11:27:37.952777Z","iopub.status.idle":"2023-11-26T11:27:37.983590Z","shell.execute_reply.started":"2023-11-26T11:27:37.952728Z","shell.execute_reply":"2023-11-26T11:27:37.982417Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# Number of records of people enrolled to bank\ndf['Exited'].value_counts()\n# As we can see the below values, there is imbalance in the classification","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:40.086459Z","iopub.execute_input":"2023-11-26T11:27:40.087487Z","iopub.status.idle":"2023-11-26T11:27:40.100490Z","shell.execute_reply.started":"2023-11-26T11:27:40.087407Z","shell.execute_reply":"2023-11-26T11:27:40.099333Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Exited\n0    7963\n1    2037\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df['Geography'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:42.314141Z","iopub.execute_input":"2023-11-26T11:27:42.314765Z","iopub.status.idle":"2023-11-26T11:27:42.326184Z","shell.execute_reply.started":"2023-11-26T11:27:42.314731Z","shell.execute_reply":"2023-11-26T11:27:42.324918Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Geography\nFrance     5014\nGermany    2509\nSpain      2477\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df['Gender'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:44.817096Z","iopub.execute_input":"2023-11-26T11:27:44.817552Z","iopub.status.idle":"2023-11-26T11:27:44.829746Z","shell.execute_reply.started":"2023-11-26T11:27:44.817517Z","shell.execute_reply":"2023-11-26T11:27:44.828508Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Gender\nMale      5457\nFemale    4543\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Dropping irrelevant columns\ndf.drop(columns = [\"RowNumber\", \"CustomerId\", \"Surname\"], inplace = True)\n# inplace = True makes the changes permanant","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:47.392897Z","iopub.execute_input":"2023-11-26T11:27:47.394324Z","iopub.status.idle":"2023-11-26T11:27:47.406435Z","shell.execute_reply.started":"2023-11-26T11:27:47.394281Z","shell.execute_reply":"2023-11-26T11:27:47.404265Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:49.458345Z","iopub.execute_input":"2023-11-26T11:27:49.458790Z","iopub.status.idle":"2023-11-26T11:27:49.478893Z","shell.execute_reply.started":"2023-11-26T11:27:49.458757Z","shell.execute_reply":"2023-11-26T11:27:49.476874Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n0          619    France  Female   42       2       0.00              1   \n1          608     Spain  Female   41       1   83807.86              1   \n2          502    France  Female   42       8  159660.80              3   \n3          699    France  Female   39       1       0.00              2   \n4          850     Spain  Female   43       2  125510.82              1   \n\n   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n0          1               1        101348.88       1  \n1          0               1        112542.58       0  \n2          1               0        113931.57       1  \n3          0               0         93826.63       0  \n4          1               1         79084.10       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# performing one-hot encoding for categorical data\nimport pandas as pd\n\n# Assuming df is your DataFrame\ndf = pd.get_dummies(df, columns=[\"Geography\", \"Gender\"], drop_first=True, dtype=np.int64)\n\n# We are dropping the firt column as 3 categories can be represented by 2 column and 2 category of gender column in one column","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:52.136125Z","iopub.execute_input":"2023-11-26T11:27:52.136536Z","iopub.status.idle":"2023-11-26T11:27:52.158142Z","shell.execute_reply.started":"2023-11-26T11:27:52.136502Z","shell.execute_reply":"2023-11-26T11:27:52.156814Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Scaling all the columns as we can see that the values of the column is not comparable\n# values of salary columns are much much higher\n# We are scaling beacuse in the time of calculation of weights it takes very long to converge\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data\nX = df.drop(columns = ['Exited'])\ny = df['Exited']","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:27:56.957243Z","iopub.execute_input":"2023-11-26T11:27:56.958633Z","iopub.status.idle":"2023-11-26T11:27:56.968470Z","shell.execute_reply.started":"2023-11-26T11:27:56.958563Z","shell.execute_reply":"2023-11-26T11:27:56.966878Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:28:01.119962Z","iopub.execute_input":"2023-11-26T11:28:01.121101Z","iopub.status.idle":"2023-11-26T11:28:02.133835Z","shell.execute_reply.started":"2023-11-26T11:28:01.120972Z","shell.execute_reply":"2023-11-26T11:28:02.131186Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:28:03.837443Z","iopub.execute_input":"2023-11-26T11:28:03.838464Z","iopub.status.idle":"2023-11-26T11:28:03.847730Z","shell.execute_reply.started":"2023-11-26T11:28:03.838402Z","shell.execute_reply":"2023-11-26T11:28:03.845444Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(8000, 11)\n(2000, 11)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Scaling the training and test data\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_trained_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n'''Scaling is a crucial step in many machine learning algorithms, and it involves standardizing or normalizing the features of your dataset. The reason for using different functions for scaling the training and testing data is to prevent data leakage and ensure that your model generalizes well to new, unseen data.\n\nWhen you scale your data, you calculate statistics (like mean and standard deviation) based on the training set and use these statistics to scale both the training and testing sets. This is why you use fit_transform on the training data—it calculates the scaling parameters (mean and standard deviation) and applies the transformation to the training set.\n\nHowever, when it comes to the testing set, you don't want to recalculate the scaling parameters because it's important that the scaling is consistent with what the model learned during training. If you used the statistics from the testing set to scale it, the model would essentially have information about the testing set during training, leading to optimistic and inaccurate performance estimates.\n\nSo, by using transform on the testing set, you apply the same scaling transformation that was learned from the training set. This ensures that the testing data is scaled in the same way as the training data, maintaining the integrity of the model evaluation on unseen data.'''\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:28:06.143593Z","iopub.execute_input":"2023-11-26T11:28:06.145058Z","iopub.status.idle":"2023-11-26T11:28:06.172268Z","shell.execute_reply.started":"2023-11-26T11:28:06.144960Z","shell.execute_reply":"2023-11-26T11:28:06.170728Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"\"Scaling is a crucial step in many machine learning algorithms, and it involves standardizing or normalizing the features of your dataset. The reason for using different functions for scaling the training and testing data is to prevent data leakage and ensure that your model generalizes well to new, unseen data.\\n\\nWhen you scale your data, you calculate statistics (like mean and standard deviation) based on the training set and use these statistics to scale both the training and testing sets. This is why you use fit_transform on the training data—it calculates the scaling parameters (mean and standard deviation) and applies the transformation to the training set.\\n\\nHowever, when it comes to the testing set, you don't want to recalculate the scaling parameters because it's important that the scaling is consistent with what the model learned during training. If you used the statistics from the testing set to scale it, the model would essentially have information about the testing set during training, leading to optimistic and inaccurate performance estimates.\\n\\nSo, by using transform on the testing set, you apply the same scaling transformation that was learned from the training set. This ensures that the testing data is scaled in the same way as the training data, maintaining the integrity of the model evaluation on unseen data.\""},"metadata":{}}]},{"cell_type":"code","source":"X_trained_scaled","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:28:09.154036Z","iopub.execute_input":"2023-11-26T11:28:09.154657Z","iopub.status.idle":"2023-11-26T11:28:09.164960Z","shell.execute_reply.started":"2023-11-26T11:28:09.154614Z","shell.execute_reply":"2023-11-26T11:28:09.163405Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([[-0.23082038, -0.94449979, -0.70174202, ...,  1.71490137,\n        -0.57273139,  0.91509065],\n       [-0.25150912, -0.94449979, -0.35520275, ..., -0.58312392,\n        -0.57273139, -1.09278791],\n       [-0.3963303 ,  0.77498705,  0.33787579, ...,  1.71490137,\n        -0.57273139, -1.09278791],\n       ...,\n       [ 0.22433188,  0.58393295,  1.3774936 , ..., -0.58312392,\n        -0.57273139, -1.09278791],\n       [ 0.13123255,  0.01077067,  1.03095433, ..., -0.58312392,\n        -0.57273139, -1.09278791],\n       [ 1.1656695 ,  0.29735181,  0.33787579, ...,  1.71490137,\n        -0.57273139,  0.91509065]])"},"metadata":{}}]},{"cell_type":"code","source":"pip install tensorFlow","metadata":{"execution":{"iopub.status.busy":"2023-11-25T18:48:03.776826Z","iopub.execute_input":"2023-11-25T18:48:03.777245Z","iopub.status.idle":"2023-11-25T18:48:20.117739Z","shell.execute_reply.started":"2023-11-25T18:48:03.777215Z","shell.execute_reply":"2023-11-25T18:48:20.115923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2023-11-26T11:28:11.433024Z","iopub.execute_input":"2023-11-26T11:28:11.433703Z","iopub.status.idle":"2023-11-26T11:28:27.391827Z","shell.execute_reply.started":"2023-11-26T11:28:11.433639Z","shell.execute_reply":"2023-11-26T11:28:27.389760Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# There are two types of model \nmodel = Sequential()\n\n# We will using 3 nodes, We use add function\n# Dense function is used to create layer\n\n# This is input layer\nmodel.add(Dense(3, activation = 'sigmoid'))\n","metadata":{},"execution_count":null,"outputs":[]}]}